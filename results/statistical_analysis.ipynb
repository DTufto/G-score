{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-01T09:59:23.964277Z",
     "start_time": "2024-11-01T09:59:18.876292Z"
    }
   },
   "source": [
    "from scipy.stats import wilcoxon, shapiro\n",
    "import pandas as pd\n",
    "import math\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T09:59:23.974052Z",
     "start_time": "2024-11-01T09:59:23.966115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_FTTSE(energy, time, is_training=True):\n",
    "    \"\"\"\n",
    "    Calculate the FTTSE (Function of Time To Solution and Energy) metric.\n",
    "    :param energy: Energy consumption in Joules\n",
    "    :param time: Time to solution in seconds\n",
    "    :param is_training: Whether the calculation is for training or inference\n",
    "    :return: FTTSE value\n",
    "    \"\"\"\n",
    "    if is_training:\n",
    "        return energy * (time**2)\n",
    "    else:\n",
    "        return energy * math.exp(time)\n",
    "\n",
    "def calculate_G_score_per_trial(data, number_of_inferences, alpha):\n",
    "    \"\"\"\n",
    "    Calculate the G-score for each model within each trial in the data.\n",
    "    :param data: DataFrame containing the data\n",
    "    :param number_of_inferences: Number of inferences to consider\n",
    "    :param alpha: Performance weight (0 <= alpha <= 1)\n",
    "    \"\"\"\n",
    "    for trial_number in data['Trial'].unique():\n",
    "        trial_data = data[data['Trial'] == trial_number].copy()  # Work with a copy for safe modification\n",
    "\n",
    "        # Calculate combined and normalized FTTSE\n",
    "        trial_data['FTTSE_combined'] = (1 - trial_data['FTTSE_Training']) + (1 - trial_data['FTTSE_Inference']) * number_of_inferences\n",
    "        fttse_min, fttse_max = trial_data['FTTSE_combined'].min(), trial_data['FTTSE_combined'].max()\n",
    "        trial_data['FTTSE_norm'] = (trial_data['FTTSE_combined'] - fttse_min) / (fttse_max - fttse_min)\n",
    "\n",
    "        # Calculate G_Score for each model within the trial\n",
    "        for model in trial_data['Model'].unique():\n",
    "            model_data = trial_data[trial_data['Model'] == model]\n",
    "            f1 = model_data['F1_Score'].values[0]\n",
    "            energy = model_data['FTTSE_norm'].values[0]\n",
    "            beta = 1 - alpha\n",
    "            g_score = alpha * f1 + beta * energy\n",
    "\n",
    "            # Assign the G_Score value to the original data\n",
    "            data.loc[(data['Trial'] == trial_number) & (data['Model'] == model), 'G_Score'] = g_score\n",
    "\n",
    "\n",
    "def test(x, y):\n",
    "    \"\"\"\n",
    "    Perform a Wilcoxon signed-rank test on the given data.\n",
    "    :param x: First data array\n",
    "    :param y: Second data array\n",
    "    :return: p-value\n",
    "    \"\"\"\n",
    "    return wilcoxon(x, y, nan_policy='omit').pvalue"
   ],
   "id": "d7503d2506c2e450",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T09:59:24.073561Z",
     "start_time": "2024-11-01T09:59:23.975510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"data/model_performance_results_20241029_050347.csv\")\n",
    "\n",
    "df['FTTSE_Training'] = df.apply(\n",
    "    lambda row: calculate_FTTSE(row['Training_Energy_Joules'], row['Training_Time_Seconds'], is_training=True), axis=1)\n",
    "df['FTTSE_Inference'] = df.apply(\n",
    "    lambda row: calculate_FTTSE(row['Inference_Energy_Joules'], row['Inference_Time_Seconds'], is_training=False), axis=1)\n",
    "\n",
    "nr_of_inferences = random.uniform(1e3, 1e9)\n",
    "alpha = random.random()\n",
    "calculate_G_score_per_trial(df, nr_of_inferences, alpha)\n",
    "\n",
    "models = df['Model'].unique()\n",
    "\n",
    "print(df)"
   ],
   "id": "6640773d76aaf001",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Trial                   Model  Training_Time_Seconds  \\\n",
      "0       1           Decision Tree                 259.62   \n",
      "1       1     Logistic Regression                  23.04   \n",
      "2       1             Naive Bayes                   8.28   \n",
      "3       1  Support Vector Machine                   8.47   \n",
      "4       2           Decision Tree                 258.72   \n",
      "..    ...                     ...                    ...   \n",
      "75     19  Support Vector Machine                   8.79   \n",
      "76     20           Decision Tree                 259.32   \n",
      "77     20     Logistic Regression                  22.43   \n",
      "78     20             Naive Bayes                   8.28   \n",
      "79     20  Support Vector Machine                   8.51   \n",
      "\n",
      "    Training_Energy_Joules  Inference_Time_Seconds  Inference_Energy_Joules  \\\n",
      "0                  3479.99                    0.04                     0.61   \n",
      "1                   735.11                    0.05                     1.38   \n",
      "2                    89.44                    1.24                    15.05   \n",
      "3                   102.88                    1.62                    51.26   \n",
      "4                  3176.29                    0.04                     0.55   \n",
      "..                     ...                     ...                      ...   \n",
      "75                  117.99                    1.62                    51.27   \n",
      "76                 3172.05                    0.04                     0.57   \n",
      "77                  714.90                    0.06                     2.04   \n",
      "78                   97.25                    1.24                    16.39   \n",
      "79                  113.49                    1.63                    51.56   \n",
      "\n",
      "    F1_Score  FTTSE_Training  FTTSE_Inference   G_Score  \n",
      "0     0.5589    2.345602e+08         0.634895  0.784507  \n",
      "1     0.5844    3.902270e+05         1.450754  0.796195  \n",
      "2     0.5760    6.131863e+03        52.006983  0.691853  \n",
      "3     0.5882    7.380704e+03       259.021410  0.287357  \n",
      "4     0.5577    2.126083e+08         0.572446  0.783920  \n",
      "..       ...             ...              ...       ...  \n",
      "75    0.5966    9.116391e+03       259.071941  0.291461  \n",
      "76    0.5555    2.133104e+08         0.593262  0.782846  \n",
      "77    0.5844    3.596697e+05         2.166147  0.794655  \n",
      "78    0.5760    6.667304e+03        56.637505  0.684286  \n",
      "79    0.5954    8.218957e+03       263.155780  0.290875  \n",
      "\n",
      "[80 rows x 10 columns]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T09:59:24.105209Z",
     "start_time": "2024-11-01T09:59:24.074575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if each column in the dataframe is normally distributed\n",
    "for column in ['FTTSE_Training', 'FTTSE_Inference', 'G_Score', 'F1_Score']:\n",
    "    for model in models:\n",
    "        data = df[df['Model'] == model][column].values\n",
    "        stat, p = shapiro(data, nan_policy='omit')\n",
    "        normally_distributed = True if p > 0.05 else False\n",
    "        print(f\"{column}, {model}: stat={stat}, p={p}, normally_distributed={normally_distributed}\")"
   ],
   "id": "1bce5f67e84c6c86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTTSE_Training, Decision Tree: stat=0.9248715046927829, p=0.13925935884419222, normally_distributed=True\n",
      "FTTSE_Training, Logistic Regression: stat=0.9525510425096398, p=0.4074801551812648, normally_distributed=True\n",
      "FTTSE_Training, Naive Bayes: stat=0.8395279929638169, p=0.0035765026841463013, normally_distributed=False\n",
      "FTTSE_Training, Support Vector Machine: stat=0.8993012878362476, p=0.040014221090994714, normally_distributed=False\n",
      "FTTSE_Inference, Decision Tree: stat=0.881804841639356, p=0.019068250647961457, normally_distributed=False\n",
      "FTTSE_Inference, Logistic Regression: stat=0.9134244009520304, p=0.07409209328647123, normally_distributed=True\n",
      "FTTSE_Inference, Naive Bayes: stat=0.8995917255412967, p=0.0405185502723816, normally_distributed=False\n",
      "FTTSE_Inference, Support Vector Machine: stat=0.9274985330697426, p=0.13820184762937382, normally_distributed=True\n",
      "G_Score, Decision Tree: stat=0.9893410175012145, p=0.997736071927819, normally_distributed=True\n",
      "G_Score, Logistic Regression: stat=0.9671565533051686, p=0.6940668654904895, normally_distributed=True\n",
      "G_Score, Naive Bayes: stat=0.9112524423917807, p=0.06733847200383576, normally_distributed=True\n",
      "G_Score, Support Vector Machine: stat=0.9610595388980299, p=0.5652282469147698, normally_distributed=True\n",
      "F1_Score, Decision Tree: stat=0.9904194733544475, p=0.9986066298668139, normally_distributed=True\n",
      "F1_Score, Logistic Regression: stat=1.0, p=1.0, normally_distributed=True\n",
      "F1_Score, Naive Bayes: stat=1.0, p=1.0, normally_distributed=True\n",
      "F1_Score, Support Vector Machine: stat=0.9610595388980296, p=0.5652282469147649, normally_distributed=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catod\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\g-score-ry8fHiCz-py3.12\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:573: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T09:59:24.142948Z",
     "start_time": "2024-11-01T09:59:24.106744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "RQ: How can we define a measure for evaluating machine learning models that takes into account both energy and performance?\n",
    "\n",
    "H0: There is no difference in G-scores among the classification models (and is therefore not a useful metric).\n",
    "H1: There is a difference in G-scores among the classification models (and is therefore a useful metric).\n",
    "\"\"\"\n",
    "\n",
    "test_results_g_score = pd.DataFrame(index=models, columns=models)\n",
    "for model1 in models:\n",
    "    for model2 in models:\n",
    "        if model1 == model2:\n",
    "            test_results_g_score.loc[model1, model2] = (0, 0, 1.0, \"Fail to reject\")\n",
    "        else:            \n",
    "            data1 = df[df['Model'] == model1]['G_Score'].values\n",
    "            data2 = df[df['Model'] == model2]['G_Score'].values\n",
    "            \n",
    "            p_value = test(data1, data2)\n",
    "            accept = \"Fail to reject\" if p_value > 0.05 else \"Reject\"\n",
    "\n",
    "            test_results_g_score.loc[model1, model2] = (p_value, accept)\n",
    "\n",
    "print(test_results_g_score)"
   ],
   "id": "9b9f9bb9cfb0bbe2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Decision Tree  \\\n",
      "Decision Tree            (0, 0, 1.0, Fail to reject)   \n",
      "Logistic Regression     (3.814697265625e-06, Reject)   \n",
      "Naive Bayes             (3.814697265625e-06, Reject)   \n",
      "Support Vector Machine  (3.814697265625e-06, Reject)   \n",
      "\n",
      "                                  Logistic Regression  \\\n",
      "Decision Tree            (3.814697265625e-06, Reject)   \n",
      "Logistic Regression       (0, 0, 1.0, Fail to reject)   \n",
      "Naive Bayes             (1.9073486328125e-06, Reject)   \n",
      "Support Vector Machine  (1.9073486328125e-06, Reject)   \n",
      "\n",
      "                                          Naive Bayes  \\\n",
      "Decision Tree            (3.814697265625e-06, Reject)   \n",
      "Logistic Regression     (1.9073486328125e-06, Reject)   \n",
      "Naive Bayes               (0, 0, 1.0, Fail to reject)   \n",
      "Support Vector Machine  (1.9073486328125e-06, Reject)   \n",
      "\n",
      "                               Support Vector Machine  \n",
      "Decision Tree            (3.814697265625e-06, Reject)  \n",
      "Logistic Regression     (1.9073486328125e-06, Reject)  \n",
      "Naive Bayes             (1.9073486328125e-06, Reject)  \n",
      "Support Vector Machine    (0, 0, 1.0, Fail to reject)  \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T09:59:24.177290Z",
     "start_time": "2024-11-01T09:59:24.144242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "RQ1: What is the energy efficiency, measured in FTTSE, of selected classification models (Naïve Bayes, Logistic Regression,\n",
    "Decision Tree, and Support Vector Machine) during training when applied to the Microsoft's Cats vs Dogs dataset?\n",
    "\n",
    "H0a: There is no difference in energy efficiency among the classification models during training.\n",
    "H1a: There is a difference in energy efficiency among the classification models during training.\n",
    "\"\"\"\n",
    "\n",
    "test_results_training = pd.DataFrame(index=models, columns=models)\n",
    "for model1 in models:\n",
    "    for model2 in models:\n",
    "        if model1 == model2:\n",
    "            test_results_training.loc[model1, model2] = (0, 0, 1.0, \"Fail to reject\")\n",
    "        else:\n",
    "            data1 = df[df['Model'] == model1]['FTTSE_Training'].values\n",
    "            data2 = df[df['Model'] == model2]['FTTSE_Training'].values\n",
    "            p_value = test(data1, data2)\n",
    "            accept = \"Fail to reject\" if p_value > 0.05 else \"Reject\"\n",
    "            \n",
    "            test_results_training.loc[model1, model2] = (p_value, accept)\n",
    "            \n",
    "            # print(f\"{model1} vs {model2}: {n_pos} positive, {n_neg} negative, p-value = {p_value}, {accept} the null hypothesis H0a\")\n",
    "            \n",
    "print(test_results_training)"
   ],
   "id": "d3e5174e5762bade",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Decision Tree  \\\n",
      "Decision Tree            (0, 0, 1.0, Fail to reject)   \n",
      "Logistic Regression     (3.814697265625e-06, Reject)   \n",
      "Naive Bayes             (3.814697265625e-06, Reject)   \n",
      "Support Vector Machine  (3.814697265625e-06, Reject)   \n",
      "\n",
      "                                  Logistic Regression  \\\n",
      "Decision Tree            (3.814697265625e-06, Reject)   \n",
      "Logistic Regression       (0, 0, 1.0, Fail to reject)   \n",
      "Naive Bayes             (1.9073486328125e-06, Reject)   \n",
      "Support Vector Machine  (1.9073486328125e-06, Reject)   \n",
      "\n",
      "                                          Naive Bayes  \\\n",
      "Decision Tree            (3.814697265625e-06, Reject)   \n",
      "Logistic Regression     (1.9073486328125e-06, Reject)   \n",
      "Naive Bayes               (0, 0, 1.0, Fail to reject)   \n",
      "Support Vector Machine  (1.9073486328125e-06, Reject)   \n",
      "\n",
      "                               Support Vector Machine  \n",
      "Decision Tree            (3.814697265625e-06, Reject)  \n",
      "Logistic Regression     (1.9073486328125e-06, Reject)  \n",
      "Naive Bayes             (1.9073486328125e-06, Reject)  \n",
      "Support Vector Machine    (0, 0, 1.0, Fail to reject)  \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T09:59:24.216930Z",
     "start_time": "2024-11-01T09:59:24.179004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "RQ2: What is the energy efficiency, measured in FTTSE, of selected classification models (Naïve Bayes, Logistic Regression,\n",
    "Decision Tree, and Support Vector Machine) during inference when applied to the Microsoft's Cats vs Dogs dataset?\n",
    "\n",
    "H0b: There is no difference in energy efficiency among the classification models during inference.\n",
    "H1b: There is a difference in energy efficiency among the classification models during inference.\n",
    "\"\"\"\n",
    "\n",
    "test_results_inference = pd.DataFrame(index=models, columns=models)\n",
    "for model1 in models:\n",
    "    for model2 in models:\n",
    "        if model1 == model2:\n",
    "            test_results_inference.loc[model1, model2] = (0, 0, 1.0, \"Fail to reject\")\n",
    "        else:\n",
    "            data1 = df[df['Model'] == model1]['FTTSE_Inference'].values\n",
    "            data2 = df[df['Model'] == model2]['FTTSE_Inference'].values\n",
    "            p_value = test(data1, data2)\n",
    "            accept = \"Fail to reject\" if p_value > 0.05 else \"Reject\"\n",
    "\n",
    "            test_results_inference.loc[model1, model2] = (p_value, accept)\n",
    "\n",
    "            # print(f\"{model1} vs {model2}: {n_pos} positive, {n_neg} negative, p-value = {p_value}, {accept} the null hypothesis H0b\")\n",
    "\n",
    "print(test_results_inference)"
   ],
   "id": "78c3e847277f0758",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Decision Tree  \\\n",
      "Decision Tree             (0, 0, 1.0, Fail to reject)   \n",
      "Logistic Regression     (1.9073486328125e-06, Reject)   \n",
      "Naive Bayes             (1.9073486328125e-06, Reject)   \n",
      "Support Vector Machine  (1.9073486328125e-06, Reject)   \n",
      "\n",
      "                                  Logistic Regression  \\\n",
      "Decision Tree           (1.9073486328125e-06, Reject)   \n",
      "Logistic Regression       (0, 0, 1.0, Fail to reject)   \n",
      "Naive Bayes             (1.9073486328125e-06, Reject)   \n",
      "Support Vector Machine  (1.9073486328125e-06, Reject)   \n",
      "\n",
      "                                          Naive Bayes  \\\n",
      "Decision Tree           (1.9073486328125e-06, Reject)   \n",
      "Logistic Regression     (1.9073486328125e-06, Reject)   \n",
      "Naive Bayes               (0, 0, 1.0, Fail to reject)   \n",
      "Support Vector Machine  (1.9073486328125e-06, Reject)   \n",
      "\n",
      "                               Support Vector Machine  \n",
      "Decision Tree           (1.9073486328125e-06, Reject)  \n",
      "Logistic Regression     (1.9073486328125e-06, Reject)  \n",
      "Naive Bayes             (1.9073486328125e-06, Reject)  \n",
      "Support Vector Machine    (0, 0, 1.0, Fail to reject)  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T09:59:24.253515Z",
     "start_time": "2024-11-01T09:59:24.218279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_results_f1_score = pd.DataFrame(index=models, columns=models)\n",
    "for model1 in models:\n",
    "    for model2 in models:\n",
    "        if model1 == model2:\n",
    "            test_results_f1_score.loc[model1, model2] = (0, 0, 1.0, \"Fail to reject\")\n",
    "        else:\n",
    "            data1 = df[df['Model'] == model1]['F1_Score'].values\n",
    "            data2 = df[df['Model'] == model2]['F1_Score'].values\n",
    "            p_value = test(data1, data2)\n",
    "            accept = \"Fail to reject\" if p_value > 0.05 else \"Reject\"\n",
    "\n",
    "            test_results_f1_score.loc[model1, model2] = (p_value, accept)\n",
    "\n",
    "print(test_results_f1_score)"
   ],
   "id": "b4a65481849b6cee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Decision Tree  \\\n",
      "Decision Tree             (0, 0, 1.0, Fail to reject)   \n",
      "Logistic Regression     (1.9073486328125e-06, Reject)   \n",
      "Naive Bayes             (1.9073486328125e-06, Reject)   \n",
      "Support Vector Machine  (1.9073486328125e-06, Reject)   \n",
      "\n",
      "                                  Logistic Regression  \\\n",
      "Decision Tree           (1.9073486328125e-06, Reject)   \n",
      "Logistic Regression       (0, 0, 1.0, Fail to reject)   \n",
      "Naive Bayes             (1.9073486328125e-06, Reject)   \n",
      "Support Vector Machine  (1.9073486328125e-06, Reject)   \n",
      "\n",
      "                                          Naive Bayes  \\\n",
      "Decision Tree           (1.9073486328125e-06, Reject)   \n",
      "Logistic Regression     (1.9073486328125e-06, Reject)   \n",
      "Naive Bayes               (0, 0, 1.0, Fail to reject)   \n",
      "Support Vector Machine  (1.9073486328125e-06, Reject)   \n",
      "\n",
      "                               Support Vector Machine  \n",
      "Decision Tree           (1.9073486328125e-06, Reject)  \n",
      "Logistic Regression     (1.9073486328125e-06, Reject)  \n",
      "Naive Bayes             (1.9073486328125e-06, Reject)  \n",
      "Support Vector Machine    (0, 0, 1.0, Fail to reject)  \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T09:59:24.257341Z",
     "start_time": "2024-11-01T09:59:24.253515Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2c00ce9b7b0b902",
   "outputs": [],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
